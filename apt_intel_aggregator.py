#!/usr/bin/env python3
"""
APT å®æ—¶å¨èƒæƒ…æŠ¥èšåˆå™¨ v2.0
è‡ªåŠ¨æ”¶é›†ã€åˆ†æã€æ­¦å™¨åŒ–æœ€æ–° APT æ‰‹æ³•

æƒ…æŠ¥æº:
- MITRE ATT&CK Enterprise
- NVD CVE Database (æœ€æ–°é«˜å±æ¼æ´)
- GitHub (æœ€æ–° PoC/Exploit)
- Exploit-DB
- APT æŠ¥å‘Š RSS

ä¾èµ–: pip install requests feedparser
"""

import requests
import json
import time
import os
from datetime import datetime, timedelta
import feedparser
from collections import defaultdict

class APTIntelAggregator:
    def __init__(self, output_dir='/tmp/apt_intel'):
        self.output_dir = output_dir
        os.makedirs(output_dir, exist_ok=True)
        
        self.sources = {
            'mitre_attack': 'https://raw.githubusercontent.com/mitre/cti/master/enterprise-attack/enterprise-attack.json',
            'nvd_cve': 'https://services.nvd.nist.gov/rest/json/cves/2.0',
            'github_api': 'https://api.github.com/search/repositories',
            'exploit_db_rss': 'https://www.exploit-db.com/rss.xml',
        }
        
        self.apt_groups = {
            'APT1': 'PLA Unit 61398 (China)',
            'APT28': 'Fancy Bear / GRU (Russia)',
            'APT29': 'Cozy Bear / SVR (Russia)',
            'APT38': 'Lazarus Group (North Korea)',
            'APT41': 'Double Dragon (China)',
            'Sandworm': 'APT44 / GRU Unit 74455 (Russia)',
            'FIN7': 'Carbanak (Cybercrime)',
        }
        
        self.intel_db = []
    
    def banner(self):
        print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘     APT å®æ—¶å¨èƒæƒ…æŠ¥èšåˆç³»ç»Ÿ v2.0                          â•‘
â•‘     Real-time APT Threat Intelligence Aggregator          â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
""")
    
    def fetch_mitre_attack(self, days=30):
        """è·å– MITRE ATT&CK æœ€è¿‘æ›´æ–°çš„æŠ€æœ¯"""
        print("[*] Fetching MITRE ATT&CK updates...")
        try:
            r = requests.get(self.sources['mitre_attack'], timeout=30)
            data = r.json()
            
            recent = []
            cutoff = datetime.now() - timedelta(days=days)
            
            for obj in data.get('objects', []):
                if obj.get('type') == 'attack-pattern':
                    modified = obj.get('modified', '')
                    if modified:
                        mod_date = datetime.strptime(modified[:10], '%Y-%m-%d')
                        if mod_date > cutoff:
                            technique = {
                                'id': obj.get('external_references', [{}])[0].get('external_id', 'Unknown'),
                                'name': obj.get('name', 'Unknown'),
                                'description': obj.get('description', '')[:200] + '...',
                                'tactics': [kcp.get('phase_name', '') for kcp in obj.get('kill_chain_phases', [])],
                                'modified': modified[:10],
                                'source': 'MITRE ATT&CK',
                                'url': f"https://attack.mitre.org/techniques/{obj.get('external_references', [{}])[0].get('external_id', '')}"
                            }
                            recent.append(technique)
            
            print(f"[+] Found {len(recent)} updated techniques (last {days} days)")
            return recent
        except Exception as e:
            print(f"[-] Error fetching MITRE: {e}")
            return []
    
    def fetch_latest_cves(self, days=7):
        """è·å–æœ€æ–°é«˜å± CVE (CVSS >= 7.0)"""
        print("[*] Fetching latest high-severity CVEs...")
        try:
            start_date = (datetime.now() - timedelta(days=days)).strftime('%Y-%m-%dT00:00:00.000')
            end_date = datetime.now().strftime('%Y-%m-%dT23:59:59.999')
            
            url = f"{self.sources['nvd_cve']}?pubStartDate={start_date}&pubEndDate={end_date}&resultsPerPage=100"
            r = requests.get(url, timeout=30)
            data = r.json()
            
            high_severity = []
            for vuln in data.get('vulnerabilities', []):
                cve = vuln.get('cve', {})
                cve_id = cve.get('id', 'Unknown')
                
                metrics = cve.get('metrics', {})
                cvss_v31 = metrics.get('cvssMetricV31', [{}])[0] if metrics.get('cvssMetricV31') else {}
                cvss_data = cvss_v31.get('cvssData', {})
                score = cvss_data.get('baseScore', 0)
                severity = cvss_data.get('baseSeverity', 'UNKNOWN')
                
                if score >= 7.0:
                    cve_info = {
                        'cve_id': cve_id,
                        'score': score,
                        'severity': severity,
                        'description': cve.get('descriptions', [{}])[0].get('value', '')[:200] + '...',
                        'published': cve.get('published', '')[:10],
                        'source': 'NVD',
                        'url': f"https://nvd.nist.gov/vuln/detail/{cve_id}"
                    }
                    high_severity.append(cve_info)
            
            print(f"[+] Found {len(high_severity)} high-severity CVEs (CVSS >= 7.0)")
            return sorted(high_severity, key=lambda x: x['score'], reverse=True)
        except Exception as e:
            print(f"[-] Error fetching CVEs: {e}")
            return []
    
    def fetch_github_pocs(self, keywords=None, days=7):
        """æœç´¢ GitHub æœ€æ–° PoC/Exploit"""
        if keywords is None:
            keywords = ['CVE-2024', 'CVE-2025', 'exploit', 'RCE', '0day', 'APT']
        
        print("[*] Searching GitHub for latest PoCs...")
        cutoff = (datetime.now() - timedelta(days=days)).strftime('%Y-%m-%d')
        pocs = []
        
        for keyword in keywords:
            try:
                url = f"{self.sources['github_api']}?q={keyword}+pushed:>{cutoff}&sort=updated&order=desc&per_page=10"
                headers = {'Accept': 'application/vnd.github.v3+json'}
                
                # å¦‚æœè®¾ç½®äº† GitHub Token (æ¨èï¼Œé¿å…é™æµ)
                github_token = os.environ.get('GITHUB_TOKEN')
                if github_token:
                    headers['Authorization'] = f'token {github_token}'
                
                r = requests.get(url, headers=headers, timeout=30)
                if r.status_code == 200:
                    results = r.json()
                    for repo in results.get('items', [])[:5]:
                        poc = {
                            'name': repo.get('full_name', 'Unknown'),
                            'url': repo.get('html_url', ''),
                            'description': repo.get('description', 'No description')[:150],
                            'stars': repo.get('stargazers_count', 0),
                            'updated': repo.get('updated_at', '')[:10],
                            'language': repo.get('language', 'Unknown'),
                            'source': 'GitHub',
                            'keyword': keyword
                        }
                        pocs.append(poc)
                else:
                    print(f"[-] GitHub API rate limit or error: {r.status_code}")
                    break
                
                time.sleep(1)  # é¿å…é™æµ
            except Exception as e:
                print(f"[-] Error searching GitHub for '{keyword}': {e}")
        
        print(f"[+] Found {len(pocs)} PoC repositories")
        return pocs
    
    def fetch_exploit_db(self, limit=20):
        """è·å– Exploit-DB æœ€æ–°æ¼æ´"""
        print("[*] Fetching Exploit-DB updates...")
        try:
            feed = feedparser.parse(self.sources['exploit_db_rss'])
            exploits = []
            
            for entry in feed.entries[:limit]:
                exploit = {
                    'title': entry.get('title', 'Unknown'),
                    'url': entry.get('link', ''),
                    'published': entry.get('published', '')[:10],
                    'source': 'Exploit-DB'
                }
                exploits.append(exploit)
            
            print(f"[+] Found {len(exploits)} new exploits")
            return exploits
        except Exception as e:
            print(f"[-] Error fetching Exploit-DB: {e}")
            return []
    
    def analyze_apt_relevance(self, intel):
        """åˆ†ææƒ…æŠ¥çš„ APT ç›¸å…³æ€§å’Œå¯æ­¦å™¨åŒ–ç¨‹åº¦"""
        apt_keywords = [
            'rce', 'remote code execution', 'remote command execution',
            'privilege escalation', 'privesc', 'lateral movement',
            'persistence', 'credential', 'bypass', 'authentication bypass',
            'supply chain', 'zero-day', '0day', 'apt', 'targeted',
            'critical', 'unauthenticated', 'pre-auth', 'arbitrary code',
        ]
        
        text = (intel.get('description', '') + ' ' + 
                intel.get('title', '') + ' ' +
                intel.get('name', '')).lower()
        
        relevance_score = sum(1 for keyword in apt_keywords if keyword in text)
        
        intel['apt_relevance'] = relevance_score
        intel['weaponizable'] = relevance_score >= 2
        
        # é¢å¤–åŠ åˆ†é¡¹
        if intel.get('score', 0) >= 9.0:  # Critical CVE
            intel['apt_relevance'] += 2
        if intel.get('stars', 0) >= 100:  # çƒ­é—¨ GitHub é¡¹ç›®
            intel['apt_relevance'] += 1
        
        return intel
    
    def generate_report(self, intel_data):
        """ç”Ÿæˆå¯è¯»æ€§å¼ºçš„æƒ…æŠ¥æŠ¥å‘Š"""
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        
        report = f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  APT å¨èƒæƒ…æŠ¥æŠ¥å‘Š                                          â•‘
â•‘  Generated: {timestamp}                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ã€æƒ…æŠ¥ç»Ÿè®¡ã€‘
æ€»æƒ…æŠ¥æ•°é‡: {intel_data['total']}
å¯æ­¦å™¨åŒ–: {intel_data['weaponizable_count']}
æ•°æ®æº: MITRE ATT&CK, NVD, GitHub, Exploit-DB

ã€Top 10 å¯æ­¦å™¨åŒ–å¨èƒæƒ…æŠ¥ã€‘

"""
        
        for i, item in enumerate(intel_data['weaponizable'][:10], 1):
            report += f"""
[{i}] {item.get('name', item.get('cve_id', item.get('title', 'Unknown')))}
    â””â”€ Source: {item['source']}
    â””â”€ APT Relevance: {item['apt_relevance']}/10 {'ğŸ”¥' if item['apt_relevance'] >= 5 else ''}
    â””â”€ Weaponizable: {'âœ“ YES' if item['weaponizable'] else 'âœ— NO'}
"""
            if 'score' in item:
                report += f"    â””â”€ CVSS Score: {item['score']} ({item['severity']})\n"
            if 'stars' in item:
                report += f"    â””â”€ GitHub Stars: {item['stars']}\n"
            if 'url' in item:
                report += f"    â””â”€ URL: {item['url']}\n"
            if 'tactics' in item and item['tactics']:
                report += f"    â””â”€ MITRE Tactics: {', '.join(item['tactics'])}\n"
        
        report += f"""

ã€åˆ†ç±»ç»Ÿè®¡ã€‘
"""
        # æŒ‰æ¥æºåˆ†ç±»
        source_counts = defaultdict(int)
        for item in intel_data['all_intel']:
            source_counts[item['source']] += 1
        
        for source, count in source_counts.items():
            report += f"  {source}: {count} æ¡\n"
        
        report += f"""

ã€è¾“å‡ºæ–‡ä»¶ã€‘
  JSON: {self.output_dir}/apt_intel_latest.json
  Report: {self.output_dir}/apt_intel_report.txt
  
ã€ä½¿ç”¨å»ºè®®ã€‘
  1. ä¼˜å…ˆå…³æ³¨ APT Relevance >= 5 çš„æƒ…æŠ¥
  2. æ£€æŸ¥ GitHub PoC å¯ç”¨æ€§
  3. äº¤å‰éªŒè¯å¤šä¸ªæ¥æº
  4. æ­¦å™¨åŒ–æµ‹è¯•åœ¨éš”ç¦»ç¯å¢ƒè¿›è¡Œ

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""
        return report
    
    def aggregate_all(self, days=7):
        """èšåˆæ‰€æœ‰å¨èƒæƒ…æŠ¥"""
        self.banner()
        
        all_intel = []
        
        # 1. MITRE ATT&CK
        mitre = self.fetch_mitre_attack(days=days)
        all_intel.extend(mitre)
        
        # 2. CVE
        cves = self.fetch_latest_cves(days=days)
        all_intel.extend(cves)
        
        # 3. GitHub PoCs
        pocs = self.fetch_github_pocs(days=days)
        all_intel.extend(pocs)
        
        # 4. Exploit-DB
        exploits = self.fetch_exploit_db()
        all_intel.extend(exploits)
        
        # åˆ†æç›¸å…³æ€§
        print("\n[*] Analyzing APT relevance...")
        analyzed = [self.analyze_apt_relevance(intel) for intel in all_intel]
        
        # æ’åºï¼ˆæŒ‰å¯æ­¦å™¨åŒ–ç¨‹åº¦ï¼‰
        weaponizable = sorted(
            [i for i in analyzed if i.get('weaponizable')],
            key=lambda x: x.get('apt_relevance', 0),
            reverse=True
        )
        
        print(f"\n[+] Total intelligence collected: {len(all_intel)}")
        print(f"[+] Weaponizable intelligence: {len(weaponizable)}")
        
        # å‡†å¤‡è¾“å‡ºæ•°æ®
        intel_data = {
            'generated': datetime.now().isoformat(),
            'total': len(all_intel),
            'weaponizable_count': len(weaponizable),
            'all_intel': analyzed,
            'weaponizable': weaponizable
        }
        
        # ä¿å­˜ JSON
        json_file = f'{self.output_dir}/apt_intel_latest.json'
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(intel_data, f, indent=2, ensure_ascii=False)
        print(f"[+] JSON saved: {json_file}")
        
        # ç”Ÿæˆå¹¶ä¿å­˜æŠ¥å‘Š
        report = self.generate_report(intel_data)
        report_file = f'{self.output_dir}/apt_intel_report.txt'
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report)
        print(f"[+] Report saved: {report_file}")
        
        # æ˜¾ç¤ºæŠ¥å‘Š
        print(report)
        
        return intel_data

def main():
    import argparse
    
    parser = argparse.ArgumentParser(description='APT å®æ—¶å¨èƒæƒ…æŠ¥èšåˆå™¨')
    parser.add_argument('-d', '--days', type=int, default=7, help='æƒ…æŠ¥æ—¶é—´èŒƒå›´ï¼ˆå¤©ï¼‰')
    parser.add_argument('-o', '--output', default='/tmp/apt_intel', help='è¾“å‡ºç›®å½•')
    parser.add_argument('--loop', action='store_true', help='æŒç»­è¿è¡Œæ¨¡å¼ï¼ˆæ¯24å°æ—¶æ›´æ–°ï¼‰')
    
    args = parser.parse_args()
    
    aggregator = APTIntelAggregator(output_dir=args.output)
    
    if args.loop:
        print("[*] Running in continuous mode (updates every 24 hours)")
        print("[*] Press Ctrl+C to stop\n")
        while True:
            try:
                aggregator.aggregate_all(days=args.days)
                print(f"\n[*] Next update in 24 hours...")
                print(f"[*] Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                time.sleep(86400)  # 24å°æ—¶
            except KeyboardInterrupt:
                print("\n[!] Stopped by user")
                break
            except Exception as e:
                print(f"[-] Error: {e}")
                print("[*] Retrying in 1 hour...")
                time.sleep(3600)
    else:
        aggregator.aggregate_all(days=args.days)

if __name__ == '__main__':
    main()
